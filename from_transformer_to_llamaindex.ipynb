{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Completion\n",
    "\n",
    "This example intends to provide a useful code with Llama_index library using a Hugginface pre-trained model to complete the prompt established as introduction for starting the conversation with the model.\n",
    "\n",
    "The objective of this example was to run a complete functional example in an on-premise GPU of only 12Gb.\n",
    "\n",
    "### References\n",
    "\n",
    "* [Tiny Llama Model](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)\n",
    "* [Llama 2 Model Description](https://ai.meta.com/resources/models-and-libraries/llama/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Code using pytorch and trasformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 12:16:55.774974: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-19 12:16:55.803408: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-19 12:16:56.349374: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a friendly chatbot who always responds in the style of a pirate</s>\n",
      "<|user|>\n",
      "How many helicopters can a human eat in one sitting?</s>\n",
      "<|assistant|>\n",
      "I do not have access to specific data on the number of helicopters a human can eat in one sitting. However, helicopters are usually equipped with a small serving capacity, and a typical meal for one person might consist of around 3-4 servings. So, a human can eat around 6-8 servings of helicopter food, which is not a lot. However, the number of servings depends on the size of the helicopter, the quality of the food, and the individual's appetite.\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. To Llamaindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import set_global_tokenizer\n",
    "# tokenizer for huggingface\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "set_global_tokenizer(\n",
    "    AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\").encode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms import HuggingFaceLLM\n",
    "from llama_index.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    model_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    tokenizer_name=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    query_wrapper_prompt=PromptTemplate(\n",
    "        \"<|system|>\\n</s>\\n<|user|>\\n</s>\\n<|assistant|>\\n\"),\n",
    "    context_window=2048,\n",
    "    max_new_tokens=256,\n",
    "    model_kwargs={'trust_remote_code': True},\n",
    "    generate_kwargs={\"temperature\": 0.7,\"do_sample\":True},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I can provide you with a list of recommended resources for learning about and practicing mindfulness. Here are some options:\n",
      "\n",
      "1. Mindfulness-Based Stress Reduction (MBSR) by Jon Kabat-Zinn. This is a comprehensive program that teaches mindfulness meditation and other techniques for managing stress, pain, and other negative emotions.\n",
      "\n",
      "2. The Mindful Way Workbook by Mark Williams and Danny Penman. This is a step-by-step guide that helps readers develop mindfulness practices and understand the science behind it.\n",
      "\n",
      "3. Mindfulness-Based Cognitive Therapy (MBCT) by Martin Seligman. This is a popular mindfulness-based approach to treating depression that emphasizes cognitive-behavioral therapy and mindfulness meditation.\n",
      "\n",
      "4. Mindfulness-Based Relaxation: A Guide to Stress Reduction (Second Edition) by Sharon Begley. This book provides step-by-step instructions for practicing mindfulness meditation and relaxation techniques, as well as scientific research on their effectiveness in reducing stress and anxiety.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_str = \"How many helicopters can a human eat in one sitting?\"\n",
    "\n",
    "response = llm.complete(query_str)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 01:37:02.033643: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-28 01:37:02.059520: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-28 01:37:02.639169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: <|assistant|>\n",
      "I do not have access to specific information about any living being's diet or nutrition. However, according to scientific studies, humans consume approximately 35 grams of energy (calories) per kg of body weight per day. In other words, you would have to consume approximately 9,000 calories (35 grams * 2,400 pounds) to sustain yourself in a single sitting, assuming you were at your full weight.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a friendly chatbot who always responds\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=query_str),\n",
    "]\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Response\n",
    "\n",
    "On January 23\n",
    "\n",
    "Humans cannot eat helicopters. Helicopters are large, mechanical vehicles made of metal and other materials that are not edible. Attempting to eat a helicopter would be extremely dangerous and impossible. If you have any concerns or thoughts related to the consumption of non-food items, it's important to seek help from a medical professional or mental health expert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bard Response\n",
    "\n",
    "On January 23\n",
    "\n",
    "\n",
    "A human cannot eat a helicopter in one sitting. Helicopters are not edible, as they are made of metal, plastic, and other materials that are not digestible by humans. Additionally, helicopters are very large and heavy, and it would be physically impossible for a human to consume one in a single sitting.\n",
    "\n",
    "It is important to note that the question of how many helicopters a human can eat in one sitting is a hypothetical one, and it is not something that should be attempted in real life. Ingesting non-edible objects can be harmful to your health, and it could even be fatal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU- RAM uses after complete the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total RAM: 31.24 GB\n",
      "Aviable RAM: 28.35 GB\n",
      "Used RAM: 2.39 GB\n",
      "\n",
      "Total GPU: 12288.0 MB\n",
      "Aviable GPU: 7641.0 MB\n",
      "Usage GPU: 4403.0 MB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import GPUtil\n",
    "import os\n",
    "# Hugging Face Tokenizers Warning: This warning is related to the parallelism feature in\n",
    "# Hugging Faceâ€™s tokenizers library. When a process that has already used parallelism\n",
    "# gets forked, it can lead to deadlocks, which is why parallelism is disabled.\n",
    "\n",
    "# Avoid using tokenizers before the fork if possible.\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "gpus = GPUtil.getGPUs()\n",
    "\n",
    "\n",
    "ram_info = psutil.virtual_memory()\n",
    "\n",
    "print(f\"Total RAM: {ram_info.total / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Aviable RAM: {ram_info.available / (1024 ** 3):.2f} GB\")\n",
    "print(f\"Used RAM: {ram_info.used / (1024 ** 3):.2f} GB\\n\")\n",
    "if gpus:\n",
    "    print(f\"Total GPU: {gpus[0].memoryTotal} MB\")\n",
    "\n",
    "    # Imprimir la cantidad de memoria GPU disponible\n",
    "    print(f\"Aviable GPU: {gpus[0].memoryFree} MB\")\n",
    "    print(f\"Usage GPU: {gpus[0].memoryUsed} MB\")\n",
    "else:\n",
    "    print(\"There aren't aviable GPU.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
