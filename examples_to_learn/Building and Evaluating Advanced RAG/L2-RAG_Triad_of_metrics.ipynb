{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6-q-gTUaZU7",
    "tags": []
   },
   "source": [
    "# Lesson 2: RAG Triad of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "height": 89
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "height": 98,
    "id": "wMvq1q8yaZU-"
   },
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "height": 81,
    "id": "sY8Oui4taZU-"
   },
   "outputs": [],
   "source": [
    "from llama_index import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".\\\n",
    "                    join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "height": 217
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b608ae9e0148a5a574ed085761d752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2f9b6a2f844e269f7a39ee66bf80f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3ee13cc905494e93a3fbc54b77983c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a061ef32ee646ea800b452f2722fa10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d7b3387cba4e009a6eccc1527cdd6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4711243e08204763aa30a57dfbe38841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import build_sentence_window_index\n",
    "\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6e6d48c94f497c8bad245993982de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f53102f8e64998885cb84dcf2e3d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a344c18ede4c6fb68b80a83850b60c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44581c7d538d47cdb4a907f6a967fd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2e004d30394898ba9b1b8f6258fb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2fac77e50e469b938d636ab74f7885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = \\\n",
    "get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To create your AI portfolio, you should focus on building a collection of projects that demonstrate your skill progression. This can be achieved by starting with simpler projects and gradually working your way up to more complex ones. By showcasing a variety of projects, you can highlight your expertise in different areas of AI. Additionally, it is important to ensure that your portfolio reflects your career goals and aligns with the type of AI job you are seeking.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = sentence_window_engine.query(\n",
    "    \"How do you create your AI portfolio?\")\n",
    "output.response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "height": 81,
    "id": "IBfdyn3MaZU9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "height": 120,
    "id": "5KqV-IbQaZVB"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "# para permitir la ejecuciÃ³n de cÃ³digo asÃ­ncrono de manera adecuada en Jupyter notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from trulens_eval import OpenAI as fOpenAI\n",
    "\n",
    "provider = fOpenAI() # llm used to run feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Answer Relevance: Is the  response relevant to the query ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "height": 226
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Feedback\n",
    "\n",
    "# feedback function provides a score after reviewing an LLM app's\n",
    "# inputs, outputs and intermediate results(context)\n",
    "f_qa_relevance = Feedback(\n",
    "    provider.relevance_with_cot_reasons, # feedback function method \n",
    "    name=\"Answer Relevance\"\n",
    ").on_input_output() # pointer to user query and app output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Context Relevance: Is the retrived context relevant to the query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "height": 91
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruLlama \n",
    "\n",
    "# pointer to retrieved contexts(intermediate results)\n",
    "context_selection = TruLlama.select_source_nodes().node.text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input statement will be set to __record__.app.query.rets.source_nodes[:].node.text .\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "f_qs_relevance = (\n",
    "    Feedback(provider.qs_relevance, # also .qs_relevance_with_cot_reasons \n",
    "             name=\"Context Relevance\")\n",
    "    .on_input()\n",
    "    .on(context_selection)\n",
    "    .aggregate(np.mean) # aggregate sacore all retrieved context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Groundedness: Is the response supported by the context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from trulens_eval.feedback import Groundedness\n",
    "\n",
    "grounded = Groundedness(groundedness_provider=provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "height": 149,
    "id": "kXJBD4gfaZVC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "f_groundedness = (\n",
    "    Feedback(grounded.groundedness_measure_with_cot_reasons,\n",
    "             name=\"Groundedness\"\n",
    "            )\n",
    "    .on(context_selection)\n",
    "    .on_output()\n",
    "    .aggregate(grounded.grounded_statements_aggregator)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the RAG application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "height": 217,
    "id": "KUDHInR-aZVC"
   },
   "outputs": [],
   "source": [
    "from trulens_eval import TruLlama\n",
    "from trulens_eval import FeedbackMode\n",
    "\n",
    "tru_recorder = TruLlama(\n",
    "    sentence_window_engine,\n",
    "    app_id=\"App_1\",\n",
    "    feedbacks=[\n",
    "        f_qa_relevance,\n",
    "        f_qs_relevance,\n",
    "        f_groundedness\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "height": 115,
    "id": "dsA3ziw1aZVD"
   },
   "outputs": [],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "eval_questions.append(\"How can I be successful in AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the keys to building a career in AI?',\n",
       " 'How can teamwork contribute to success in AI?',\n",
       " 'What is the importance of networking in AI?',\n",
       " 'What are some good habits to develop for a successful career?',\n",
       " 'How can altruism be beneficial in building a career?',\n",
       " 'What is imposter syndrome and how does it relate to AI?',\n",
       " 'Who are some accomplished individuals who have experienced imposter syndrome?',\n",
       " 'What is the first step to becoming good at AI?',\n",
       " 'What are some common challenges in AI?',\n",
       " 'Is it normal to find parts of AI challenging?',\n",
       " 'How can I be successful in AI?']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 64,
    "id": "01_P6TxaaZVD"
   },
   "outputs": [],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder as recording:\n",
    "        sentence_window_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47,
    "id": "sNPhDde6ZArq"
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "records[[\"input\", \"output\"] + feedback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30,
    "id": "6Yp4_e4faZVD"
   },
   "outputs": [],
   "source": [
    "tru.run_dashboard()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1ChKW1kEIUcUVDDTWjpA5Tf_ib3Hhp3uS",
     "timestamp": 1695164681916
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
