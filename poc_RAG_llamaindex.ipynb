{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Proof of concepts in RAG**\n",
    "Compare the resource usage of some small LLMs of Hugging Face in Advanced RAG. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the resources used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import GPUtil\n",
    "import time\n",
    "\n",
    "\n",
    "def performance_metrics(function):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        ram_info = psutil.virtual_memory()\n",
    "        init_ram = ram_info.available / (1024 ** 3)\n",
    "        init_gpu = gpus[0].memoryFree\n",
    "        start_time = time.time()\n",
    "\n",
    "        out = function(*args, **kwargs)\n",
    "\n",
    "        gpus = GPUtil.getGPUs()\n",
    "        ram_info = psutil.virtual_memory()\n",
    "        print(\n",
    "            f'Used RAM: {round(init_ram - ram_info.available / (1024 ** 3),3)} GB')\n",
    "        print(f'Used GPU: {round(init_gpu - gpus[0].memoryFree,3)} MB')\n",
    "        print(f'Consumed time {time.time() - start_time} seconds')\n",
    "\n",
    "        return out\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Hugging Face Tokenizers Warning: This warning is related to the parallelism feature in \n",
    "# Hugging Faceâ€™s tokenizers library. When a process that has already used parallelism\n",
    "# gets forked, it can lead to deadlocks, which is why parallelism is disabled.\n",
    "\n",
    "# Avoid using tokenizers before the fork if possible.\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index import SimpleDirectoryReader\n",
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.embeddings import resolve_embed_model\n",
    "from llama_index.llms import HuggingFaceLLM\n",
    "from llama_index.prompts import PromptTemplate\n",
    "from llama_index import VectorStoreIndex, StorageContext, ServiceContext\n",
    "from llama_index import load_index_from_storage\n",
    "\n",
    "\n",
    "@performance_metrics\n",
    "def build_index(files, embed_model='local:BAAI/bge-large-en-v1.5',\n",
    "                model='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
    "                model_kwargs={'trust_remote_code': True},\n",
    "                generate_kwargs={\"temperature\": 0.7, \"do_sample\": True},\n",
    "                persist_dir='LLM_TRAIN/sentence_index'):\n",
    "\n",
    "    documents = SimpleDirectoryReader(input_files=files).load_data()\n",
    "\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=3,\n",
    "        window_metadata_key=\"window\",\n",
    "        include_prev_next_rel=True,\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    embed_model = resolve_embed_model(embed_model)\n",
    "    llm = HuggingFaceLLM(\n",
    "        model_name=model,\n",
    "        tokenizer_name=model,\n",
    "        query_wrapper_prompt=PromptTemplate(\n",
    "            \"<|system|>\\n</s>\\n<|user|>\\n{query_str}</s>\\n<|assistant|>\\n\"),\n",
    "        context_window=2048,  # 4096\n",
    "        max_new_tokens=256,  # 512\n",
    "        model_kwargs=model_kwargs,\n",
    "        generate_kwargs=generate_kwargs,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    sentence_context = ServiceContext.from_defaults(\n",
    "        llm=llm,\n",
    "        embed_model=embed_model,\n",
    "        node_parser=node_parser,\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(persist_dir):\n",
    "        sentence_index = VectorStoreIndex.from_documents(\n",
    "            documents, service_context=sentence_context\n",
    "        )\n",
    "\n",
    "        sentence_index.storage_context.persist(persist_dir=persist_dir)\n",
    "\n",
    "    else:\n",
    "        # print('Loading index from disk')\n",
    "        sentence_index = load_index_from_storage(\n",
    "            StorageContext.from_defaults(persist_dir=persist_dir),\n",
    "            service_context=sentence_context)\n",
    "\n",
    "    return sentence_index\n",
    "\n",
    "\n",
    "@performance_metrics\n",
    "def query_index(index, question):\n",
    "\n",
    "    # This takes a value stored in the metadata and replaces a node text\n",
    "    postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "\n",
    "    sentence_window_engine = index.as_query_engine(\n",
    "        similarity_top_k=3,  # fetch the most similarity\n",
    "        node_postprocessors=[postproc])\n",
    "\n",
    "    result = sentence_window_engine.query(question)\n",
    "    return {\n",
    "        'query': question,\n",
    "        'response': result.response,\n",
    "        'documents': [node.metadata['file_name'] for node in result.source_nodes],\n",
    "        'pages': [node.metadata['page_label'] for node in result.source_nodes]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LLM**: TinyLlama/TinyLlama-1.1B-Chat-v1.0 [$^{\\textbf{[source]}}$](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used RAM: 2.276 GB\n",
      "Used GPU: 5623.0 MB\n",
      "Consumed time 7.663482666015625 seconds\n"
     ]
    }
   ],
   "source": [
    "sentence_index = build_index(\n",
    "    files=[\"LLM_TRAIN/eBook-How-to-Build-a-Career-in-AI.pdf\"],\n",
    "    embed_model=\"local:BAAI/bge-large-en-v1.5\",\n",
    "    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    persist_dir=\"LLM_TRAIN/sentence_index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used RAM: 0.047 GB\n",
      "Used GPU: 254.0 MB\n",
      "Consumed time 3.1760852336883545 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the keys to building a career in AI?',\n",
       " 'response': 'The keys to building a career in AI are learning foundational technical skills, working on projects, and finding a job. These steps stack on top of each other and are part of a broader process of gaining experience, building a portfolio, and finding a job. Chapters with focused topics on learning foundational technical skills include learning about AI concepts and methodologies, building a portfolio, and creating impact. The key to building a career in AI is to focus on learning foundational skills, working on projects, and finding a job, all of which are supported by being part of a community.',\n",
       " 'documents': ['eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       "  'eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       "  'eBook-How-to-Build-a-Career-in-AI.pdf'],\n",
       " 'pages': ['9', '6', '35']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_response = query_index(sentence_index,\n",
    "      \"What are the keys to building a career in AI?\")\n",
    "dict_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LLM:** zephyr-7b-alpha [$^{\\textbf{[source]}}$](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha) with quantization of 4-bits \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d5bad6795f4abd92d6f5aba19eb9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used RAM: 3.159 GB\n",
      "Used GPU: 5991.0 MB\n",
      "Consumed time 13.527836561203003 seconds\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# huggingface api token\n",
    "# hf_token = 'hf_token'\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "\n",
    "sentence_index = build_index(\n",
    "    files=[\"LLM_TRAIN/eBook-How-to-Build-a-Career-in-AI.pdf\"],\n",
    "    embed_model=\"local:BAAI/bge-large-en-v1.5\",\n",
    "    model=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
    "    model_kwargs={\"quantization_config\": quantization_config},\n",
    "    generate_kwargs={\"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95, \"do_sample\":True},\n",
    "    persist_dir=\"LLM_TRAIN/sentence_index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-manuel@datwit.com/.local/lib/python3.9/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "2024-01-27 23:46:56.917487: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-27 23:46:56.944786: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-27 23:46:57.574145: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used RAM: 0.084 GB\n",
      "Used GPU: 294.0 MB\n",
      "Consumed time 7.929395437240601 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the keys to building a career in AI?',\n",
       " 'response': 'According to the given context information, the keys to building a career in AI are:\\n\\n1. Learning foundational technical skills (Chapter 1)\\n2. Working on meaningful projects to deepen skills, build a portfolio, and create impact (Chapter 2)\\n3. Finding a job (Chapter 3)\\n\\nIn addition to these three key steps, here are additional things to think about as you plot your path to success:\\n\\n- Working in teams for large projects\\n\\nThese keys to building a career in AI are outlined in Chapter 10, which is covered in the eBook.',\n",
       " 'documents': ['eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       "  'eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       "  'eBook-How-to-Build-a-Career-in-AI.pdf'],\n",
       " 'pages': ['9', '6', '35']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_response = query_index(sentence_index,\n",
    "      \"What are the keys to building a career in AI?\")\n",
    "dict_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used RAM: -0.001 GB\n",
      "Used GPU: 4.0 MB\n",
      "Consumed time 11.548146963119507 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are steps to take when finding projects to build your experience?',\n",
       " 'response': '1. Identify areas that interest you: Look for industries and sectors that align with your interests and passions.\\n2. Research and gather information: Once you have identified potential areas, research to understand the current trends, challenges, and opportunities.\\n3. Network and collaborate: Connect with people who have experience in those sectors and work collaboratively to gain insights and build relationships.\\n4. Identify meaningful projects: Consider the technical complexity and business impact of potential projects and determine which ones could serve as meaningful stepping stones.\\n5. Avoid analysis paralysis: Don\\'t spend too much time deciding which project to work on. Choose one that interests you and move forward with it.\\n6. Gain experience: Work on projects that will help you gain experience and build your portfolio.\\n7. Learn from others: Collaborate with others and learn from their experiences and insights.\\n8. Continuously learn and grow: Keep learning and growing to stay up-to-date with the latest trends and technologies.\\n\\nNote: These steps are based on the context information provided in the eBook \"How to Build a Career in AI\" by Andrew Ng.',\n",
       " 'documents': ['eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       "  'eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       "  'eBook-How-to-Build-a-Career-in-AI.pdf'],\n",
       " 'pages': ['15', '20', '19']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_index(\n",
    "    sentence_index, \"What are steps to take when finding projects to build your experience?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LLM:** Phi-1_5: a 1.3B by Microsoft Research [$^{\\textbf{[source]}}$](https://huggingface.co/microsoft/phi-1_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used RAM: 4.068 GB\n",
      "Used GPU: 6819.0 MB\n",
      "Consumed time 9.75664210319519 seconds\n"
     ]
    }
   ],
   "source": [
    "# Phi-2 does not fit in memory\n",
    "# {Used RAM: 5.811 GB\n",
    "# Used GPU: 10429.0 MB\n",
    "# Consumed time 197. seconds}\n",
    "\n",
    "sentence_index = build_index(\n",
    "    files=[\"LLM_TRAIN/eBook-How-to-Build-a-Career-in-AI.pdf\"],\n",
    "    embed_model='local:BAAI/bge-large-en-v1.5',\n",
    "    model =   \"microsoft/phi-1_5\",\n",
    "    persist_dir=\"LLM_TRAIN/sentence_index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used RAM: 0.007 GB\n",
      "Used GPU: 0.0 MB\n",
      "Consumed time 5.750103712081909 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the keys to building a career in AI?',\n",
       " 'response': 'Context information is below.\\n---------------------\\npage_label: 35\\nfile_path: LLM_TRAIN/eBook-How-to-Build-a-Career-in-AI.pdf\\n\\nPAGE 35Keys to Building a Career in AI CHAPTER 11\\nThe path to career success in AI is more complex than what I can  cover in one short eBook. \\n Hopefully the previous chapters will give you momentum to move forward. \\n Here are additional things to think about as you plot your path to success: \\nWhen we tackle large projects, we succeed better by \\nworking in teams than individually.\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: What are the keys to building a career in AI?\\nAnswer: </s>\\n<|assistant|>\\nContext information is below.\\n---------------------\\npage_label: 35\\nfile_path: LLM_TRAIN/eBook-How-to-Build-a-Career-in-AI.pdf\\n\\nPAGE 35Keys to Building a Career in AI CHAPTER 12\\nThe path to career success in AI is more complex than what I can  cover in',\n",
       " 'documents': ['eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       "  'eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       "  'eBook-How-to-Build-a-Career-in-AI.pdf'],\n",
       " 'pages': ['9', '6', '35']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_response = query_index(sentence_index,\n",
    "      \"What are the keys to building a career in AI?\")\n",
    "dict_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LLM:** TinyDolphin-2.8-1.1b [$^{\\textbf{[source]}}$](https://huggingface.co/cognitivecomputations/TinyDolphin-2.8-1.1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used RAM: 2.215 GB\n",
      "Used GPU: 5649.0 MB\n",
      "Consumed time 7.947089195251465 seconds\n"
     ]
    }
   ],
   "source": [
    "# Phi-2 does not fit in memory\n",
    "# {Used RAM: 5.811 GB\n",
    "# Used GPU: 10429.0 MB\n",
    "# Consumed time 197. seconds}\n",
    "\n",
    "sentence_index = build_index(\n",
    "    files=[\"LLM_TRAIN/eBook-How-to-Build-a-Career-in-AI.pdf\"],\n",
    "    model =   \"cognitivecomputations/TinyDolphin-2.8-1.1b\",\n",
    "    embed_model='local:BAAI/bge-large-en-v1.5',\n",
    "    persist_dir=\"LLM_TRAIN/sentence_index\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used RAM: 0.025 GB\n",
      "Used GPU: 256.0 MB\n",
      "Consumed time 6.055798053741455 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What are the keys to building a career in AI?',\n",
       " 'response': \"As a learning machine, I am eager to help you build a career in AI. I'll provide you with the \\nfoundational skills you need, along with valuable projects and resources to help you \\naccelerate your journey. \\n\\nIn more detail, here are some key steps to building a career in AI:\\n\\n1. **Learning Foundational Skills**: The first step in building a career in AI is learning the principles and techniques of building artificial intelligence. This includes concepts such as data science, machine learning, and advanced computing.\\n\\n2. **Working on Projects**: Building a career in AI is all about creating impactful solutions that solve real-world problems. This involves working on projects that challenge your skills and drive your career forward.\\n\\n3. **Finding a Job**: Once you have the skills and projects you've developed, you'll need to find a job. There are many job opportunities in the field of artificial intelligence, such as AI engineers, data scientists, and machine learning experts.\\n\\n4. **Refining Your Skills**: Over time, you'll learn and refine your skills. This\",\n",
       " 'documents': ['eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       "  'eBook-How-to-Build-a-Career-in-AI.pdf',\n",
       "  'eBook-How-to-Build-a-Career-in-AI.pdf'],\n",
       " 'pages': ['9', '6', '35']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_response = query_index(sentence_index,\n",
    "      \"What are the keys to building a career in AI?\")\n",
    "dict_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| LLM                         | Used RAM | Used GPU | Time (seconds)        | Notes                                          |\n",
    "|-----------------------------|----------|----------|-----------------------|------------------------------------------------|\n",
    "| TinyLlama-1.1B-Chat-v1.0    | 2.276 GB | 5623.0 MB| 7.66348               | Respuestas acordes                                      | \n",
    "| zephyr-7b-alpha (4-bit)     | 3.159 GB | 5991.0 MB| 13.5278               |   Respuestas acordes                                             |\n",
    "| Phi-2: a 2.7B               | 5.811 GB | 10429.0 MB| N/A                   | no queda memoria para las prediciones                          |\n",
    "| Phi-1_5: a 1.3B             | 4.068 GB | 6819.0 MB| 9.75664               | Respuestas de baja calidad, reproduce el contexto  |\n",
    "|   TinyDolphin-2.8-11b                          |    2.215 GB       |      5649.0 MB    |      7.94708                 |     Respuestas acordes                                           |\n",
    "|                             |          |          |                       |                                                |\n",
    "|                             |          |          |                       |                                                |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
